{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de1cba71",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "Comenzaremos con una visión general de cómo funcionan los modelos de aprendizaje automático y cómo se utilizan. Esto puede parecer básico si ya has trabajado en modelado estadístico o aprendizaje automático. No te preocupes, pronto avanzaremos hacia la construcción de modelos poderosos.\n",
    "\n",
    "En este curso, construirás modelos a medida que avances siguiendo el siguiente escenario:\n",
    "\n",
    "Tu primo ha ganado millones de dólares especulando con bienes raíces. Te ha ofrecido asociarte en los negocios debido a tu interés en la ciencia de datos. Él aportará el dinero y tú aportarás modelos que predigan el valor de diversas casas.\n",
    "\n",
    "Le preguntas a tu primo cómo ha predicho los valores de los bienes raíces en el pasado, y él dice que solo es intuición. Pero al hacerle más preguntas, descubres que ha identificado patrones de precios de casas que ha visto en el pasado, y utiliza esos patrones para hacer predicciones sobre nuevas casas que está considerando.\n",
    "\n",
    "El aprendizaje automático funciona de la misma manera. Comenzaremos con un modelo llamado Árbol de Decisión. Hay modelos más sofisticados que ofrecen predicciones más precisas. Pero los árboles de decisión son fáciles de entender y son el bloque de construcción básico de algunos de los mejores modelos en ciencia de datos.\n",
    "\n",
    "Para simplificar, comenzaremos con el árbol de decisión más simple posible.\n",
    "\n",
    "Divide las casas en solo dos categorías. El precio pronosticado para cualquier casa en consideración es el precio promedio histórico de las casas en la misma categoría.\n",
    "\n",
    "Utilizamos datos para decidir cómo dividir las casas en dos grupos, y luego nuevamente para determinar el precio pronosticado en cada grupo. Este paso de capturar patrones a partir de los datos se denomina ajuste o entrenamiento del modelo. Los datos utilizados para ajustar el modelo se llaman datos de entrenamiento.\n",
    "\n",
    "Los detalles de cómo se ajusta el modelo (por ejemplo, cómo dividir los datos) son lo suficientemente complejos como para dejarlos para más adelante. Después de que el modelo se haya ajustado, puedes aplicarlo a nuevos datos para predecir los precios de hogares adicionales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935047d1",
   "metadata": {},
   "source": [
    "### Mejorando el Árbol de Decisión\n",
    "¿Cuál de los dos árboles de decisión siguientes es más probable que resulte del ajuste de los datos de entrenamiento de bienes raíces?\n",
    "\n",
    "Primeros Árboles de Decisión\n",
    "\n",
    "El árbol de decisión de la izquierda (Árbol de Decisión 1) probablemente tiene más sentido, porque captura la realidad de que las casas con más habitaciones tienden a venderse a precios más altos que las casas con menos habitaciones. La mayor limitación de este modelo es que no captura la mayoría de los factores que afectan el precio de la vivienda, como el número de baños, el tamaño del lote, la ubicación, etc.\n",
    "\n",
    "Puedes capturar más factores utilizando un árbol que tenga más \"divisiones\". A estos se les llama árboles \"más profundos\". Un árbol de decisión que también considere el tamaño total del lote de cada casa podría verse así: Árbol de Profundidad 2\n",
    "\n",
    "Predices el precio de cualquier casa siguiendo el árbol de decisión, siempre eligiendo el camino correspondiente a las características de esa casa. El precio pronosticado para la casa se encuentra en la parte inferior del árbol. El punto en la parte inferior donde realizamos una predicción se llama hoja.\n",
    "\n",
    "Las divisiones y los valores en las hojas se determinarán mediante los datos, así que es hora de que revises los datos con los que trabajarás.\n",
    "\n",
    "### Usando Pandas para familiarizarte con tus datos\n",
    "El primer paso en cualquier proyecto de aprendizaje automático es familiarizarse con los datos. Utilizarás la biblioteca Pandas para esto. Pandas es la principal herramienta que utilizan los científicos de datos para explorar y manipular datos. La mayoría de las personas abrevian pandas en su código como pd. Hacemos esto con el comando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc33c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d5d9bc",
   "metadata": {},
   "source": [
    "### Seleccionando datos para el modelado\n",
    "Tu conjunto de datos tiene demasiadas variables como para entenderlo completamente, e incluso para imprimirlo de manera ordenada. ¿Cómo puedes reducir esta abrumadora cantidad de datos a algo que puedas entender?\n",
    "\n",
    "Comenzaremos seleccionando algunas variables utilizando nuestra intuición. En cursos posteriores, se te mostrarán técnicas estadísticas para priorizar automáticamente las variables.\n",
    "\n",
    "Para elegir variables/columnas, necesitaremos ver una lista de todas las columnas en el conjunto de datos. Esto se hace con la propiedad \"columns\" del DataFrame (la última línea de código a continuación)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d6329b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Suburb', 'Address', 'Rooms', 'Type', 'Price', 'Method', 'SellerG',\n",
       "       'Date', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car',\n",
       "       'Landsize', 'BuildingArea', 'YearBuilt', 'CouncilArea', 'Lattitude',\n",
       "       'Longtitude', 'Regionname', 'Propertycount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "melbourn_data = pd.read_csv(\"melb_data.csv\")\n",
    "melbourn_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1711da23",
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourn_data = melbourn_data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c8706d",
   "metadata": {},
   "source": [
    "Por convención, el objetivo de predicción se llama y. Entonces, el código que necesitamos para guardar los precios de las casas en los datos de Melbourne es el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f121a4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = melbourn_data.Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfe77fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "caracteristicas = [\"Rooms\",\"Bathroom\",\"Landsize\",\"Lattitude\",\"Longtitude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5e3773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = melbourn_data[caracteristicas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e204dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.931407</td>\n",
       "      <td>1.576340</td>\n",
       "      <td>471.006940</td>\n",
       "      <td>-37.807904</td>\n",
       "      <td>144.990201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.971079</td>\n",
       "      <td>0.711362</td>\n",
       "      <td>897.449881</td>\n",
       "      <td>0.075850</td>\n",
       "      <td>0.099165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-38.164920</td>\n",
       "      <td>144.542370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>-37.855438</td>\n",
       "      <td>144.926198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>373.000000</td>\n",
       "      <td>-37.802250</td>\n",
       "      <td>144.995800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>628.000000</td>\n",
       "      <td>-37.758200</td>\n",
       "      <td>145.052700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>37000.000000</td>\n",
       "      <td>-37.457090</td>\n",
       "      <td>145.526350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Rooms     Bathroom      Landsize    Lattitude   Longtitude\n",
       "count  6196.000000  6196.000000   6196.000000  6196.000000  6196.000000\n",
       "mean      2.931407     1.576340    471.006940   -37.807904   144.990201\n",
       "std       0.971079     0.711362    897.449881     0.075850     0.099165\n",
       "min       1.000000     1.000000      0.000000   -38.164920   144.542370\n",
       "25%       2.000000     1.000000    152.000000   -37.855438   144.926198\n",
       "50%       3.000000     1.000000    373.000000   -37.802250   144.995800\n",
       "75%       4.000000     2.000000    628.000000   -37.758200   145.052700\n",
       "max       8.000000     8.000000  37000.000000   -37.457090   145.526350"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ddb21dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>-37.8079</td>\n",
       "      <td>144.9934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>-37.8093</td>\n",
       "      <td>144.9944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rooms  Bathroom  Landsize  Lattitude  Longtitude\n",
       "1      2       1.0     156.0   -37.8079    144.9934\n",
       "2      3       2.0     134.0   -37.8093    144.9944"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8a28b1",
   "metadata": {},
   "source": [
    "### Construyendo tu modelo\n",
    "Utilizarás la biblioteca scikit-learn para crear tus modelos. Cuando escribas el código, esta biblioteca se llama sklearn, como verás en el código de ejemplo. Scikit-learn es fácilmente la biblioteca más popular para modelar los tipos de datos que se suelen almacenar en DataFrames.\n",
    "\n",
    "Los pasos para construir y utilizar un modelo son los siguientes:\n",
    "\n",
    "* Definir: ¿Qué tipo de modelo será? ¿Un árbol de decisión? ¿Algún otro tipo de modelo? También se especifican otros parámetros del tipo de modelo.\n",
    "* Ajustar (Fit): Capturar patrones a partir de los datos proporcionados. Este es el corazón del modelado.\n",
    "* Predecir: Exactamente lo que suena, hacer predicciones.\n",
    "* Evaluar: Determinar qué tan precisas son las predicciones del modelo.\n",
    "Aquí tienes un ejemplo de cómo definir un modelo de árbol de decisión con scikit-learn y ajustarlo con las características y la variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d8282c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "melbourn_model = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# entrenando el modelo\n",
    "\n",
    "melbourn_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "988ed3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haciendo predicciones para las siguientes 5 casas\n",
      "   Rooms  Bathroom  Landsize  Lattitude  Longtitude\n",
      "1      2       1.0     156.0   -37.8079    144.9934\n",
      "2      3       2.0     134.0   -37.8093    144.9944\n",
      "4      4       1.0     120.0   -37.8072    144.9941\n",
      "6      3       2.0     245.0   -37.8024    144.9993\n",
      "7      2       1.0     256.0   -37.8060    144.9954\n",
      "Las predicciones\n",
      "[1035000. 1465000. 1600000. 1876000. 1636000.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Haciendo predicciones para las siguientes 5 casas\")\n",
    "print(X.head())\n",
    "print(\"Las predicciones\")\n",
    "print(melbourn_model.predict(X.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66000a3",
   "metadata": {},
   "source": [
    "Has construido un modelo. Pero, ¿qué tan bueno es?\n",
    "\n",
    "En esta lección, aprenderás a utilizar la validación del modelo para medir la calidad de tu modelo. Medir la calidad del modelo es clave para mejorar iterativamente tus modelos.\n",
    "\n",
    "¿Qué es la validación del modelo?\n",
    "Querrás evaluar casi todos los modelos que construyas. En la mayoría (aunque no en todos) de los casos, la medida relevante de la calidad del modelo es la precisión predictiva. En otras palabras, ¿las predicciones del modelo serán cercanas a lo que realmente sucede?\n",
    "\n",
    "Muchas personas cometen un gran error al medir la precisión predictiva. Realizan predicciones con sus datos de entrenamiento y comparan esas predicciones con los valores objetivo en los datos de entrenamiento. Veremos el problema con este enfoque y cómo resolverlo en un momento, pero primero pensemos cómo haríamos esto.\n",
    "\n",
    "Primero, tendrías que resumir la calidad del modelo de una manera comprensible. Si comparas los valores predichos y reales de las viviendas para 10,000 casas, es probable que encuentres una mezcla de predicciones buenas y malas. Revisar una lista de 10,000 valores predichos y reales sería inútil. Necesitamos resumir esto en una única métrica.\n",
    "\n",
    "Existen muchas métricas para resumir la calidad del modelo, pero comenzaremos con una llamada Error Absoluto Medio (también conocido como MAE, por sus siglas en inglés). Desglosemos esta métrica comenzando por la última palabra, error.\n",
    "\n",
    "El error de predicción para cada casa es:\n",
    "\n",
    "error = real - predicho\n",
    "Entonces, si una casa cuesta $150,000 y predijiste que costaría $100,000, el error es de $50,000.\n",
    "\n",
    "Con la métrica MAE, tomamos el valor absoluto de cada error. Esto convierte cada error en un número positivo. Luego, calculamos el promedio de esos errores absolutos. Esta es nuestra medida de calidad del modelo. En términos sencillos, se puede decir:\n",
    "\n",
    "En promedio, nuestras predicciones están equivocadas por aproximadamente X.\n",
    "\n",
    "Para calcular el MAE, primero necesitamos un modelo. Ese modelo está construido en una celda oculta a continuación, que puedes revisar haciendo clic en el botón de código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e5e6ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1149.0477727566172"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "predicted_home_prices = melbourn_model.predict(X)\n",
    "mean_absolute_error(y, predicted_home_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4609afe",
   "metadata": {},
   "source": [
    "El problema con las puntuaciones \"en la muestra\"\n",
    "La medida que acabamos de calcular se puede llamar una puntuación \"en la muestra\". Utilizamos una única \"muestra\" de viviendas tanto para construir el modelo como para evaluarlo. Aquí está el problema con esto.\n",
    "\n",
    "Imagina que, en el gran mercado inmobiliario, el color de la puerta no tiene relación con el precio de la vivienda.\n",
    "\n",
    "Sin embargo, en la muestra de datos que utilizaste para construir el modelo, todas las viviendas con puertas verdes eran muy caras. El trabajo del modelo es encontrar patrones que predigan los precios de las viviendas, por lo que detectará este patrón y siempre pronosticará precios altos para las viviendas con puertas verdes.\n",
    "\n",
    "Dado que este patrón se derivó de los datos de entrenamiento, el modelo parecerá preciso en los datos de entrenamiento.\n",
    "\n",
    "Pero si este patrón no se cumple cuando el modelo ve nuevos datos, el modelo sería muy impreciso cuando se utiliza en la práctica.\n",
    "\n",
    "Dado que el valor práctico de los modelos radica en hacer predicciones sobre nuevos datos, medimos su rendimiento en datos que no se utilizaron para construir el modelo. La forma más sencilla de hacer esto es excluir algunos datos del proceso de construcción del modelo y luego usar esos datos para evaluar la precisión del modelo en datos que no ha visto antes. A estos datos se les llama datos de validación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16f3732",
   "metadata": {},
   "source": [
    "El problema con las puntuaciones \"en la muestra\"\n",
    "La medida que acabamos de calcular se puede llamar una puntuación \"en la muestra\". Utilizamos una única \"muestra\" de viviendas tanto para construir el modelo como para evaluarlo. Aquí está el problema con esto.\n",
    "\n",
    "Imagina que, en el gran mercado inmobiliario, el color de la puerta no tiene relación con el precio de la vivienda.\n",
    "\n",
    "Sin embargo, en la muestra de datos que utilizaste para construir el modelo, todas las viviendas con puertas verdes eran muy caras. El trabajo del modelo es encontrar patrones que predigan los precios de las viviendas, por lo que detectará este patrón y siempre pronosticará precios altos para las viviendas con puertas verdes.\n",
    "\n",
    "Dado que este patrón se derivó de los datos de entrenamiento, el modelo parecerá preciso en los datos de entrenamiento.\n",
    "\n",
    "Pero si este patrón no se cumple cuando el modelo ve nuevos datos, el modelo sería muy impreciso cuando se utiliza en la práctica.\n",
    "\n",
    "Dado que el valor práctico de los modelos radica en hacer predicciones sobre nuevos datos, medimos su rendimiento en datos que no se utilizaron para construir el modelo. La forma más sencilla de hacer esto es excluir algunos datos del proceso de construcción del modelo y luego usar esos datos para evaluar la precisión del modelo en datos que no ha visto antes. A estos datos se les llama datos de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f68a2e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289567.58225806453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "melbourne_model = DecisionTreeClassifier()\n",
    "\n",
    "# entrenando el modelo\n",
    "\n",
    "melbourne_model.fit(train_X, train_y)\n",
    "\n",
    "val_prediccion = melbourne_model.predict(test_X)\n",
    "print(mean_absolute_error(test_y, val_prediccion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76aad20",
   "metadata": {},
   "source": [
    "¡Wow!\n",
    "\n",
    "El error absoluto medio para los datos dentro de la muestra fue de aproximadamente 1100 dólares. Sin embargo, para los datos fuera de la muestra, es de más de 360,000 dólares.\n",
    "\n",
    "Esta diferencia representa la brecha entre un modelo que es casi exactamente correcto y uno que no es utilizable para la mayoría de los propósitos prácticos. Como punto de referencia, el valor promedio de las viviendas en los datos de validación es de 1.1 millones de dólares. Por lo tanto, el error en los nuevos datos es aproximadamente una cuarta parte del valor promedio de una vivienda.\n",
    "\n",
    "Existen muchas formas de mejorar este modelo, como experimentar para encontrar mejores características o diferentes tipos de modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6103e0",
   "metadata": {},
   "source": [
    "Al final de este paso, comprenderás los conceptos de subajuste (underfitting) y sobreajuste (overfitting), y podrás aplicar estas ideas para hacer que tus modelos sean más precisos.\n",
    "\n",
    "Experimentando con diferentes modelos\n",
    "Ahora que tienes una forma confiable de medir la precisión del modelo, puedes experimentar con modelos alternativos y ver cuál proporciona las mejores predicciones. Pero ¿qué alternativas tienes para los modelos?\n",
    "\n",
    "Puedes ver en la documentación de scikit-learn que el modelo de árbol de decisión tiene muchas opciones (más de las que necesitarás por un largo tiempo). Las opciones más importantes determinan la profundidad del árbol. Recuerda de la primera lección de este curso que la profundidad de un árbol es una medida de cuántas divisiones realiza antes de llegar a una predicción. Este es un árbol relativamente poco profundo.\n",
    "\n",
    "En la práctica, no es raro que un árbol tenga 10 divisiones entre el nivel superior (todas las casas) y una hoja. A medida que el árbol se vuelve más profundo, el conjunto de datos se divide en hojas con menos casas. Si un árbol solo tuviera 1 división, dividiría los datos en 2 grupos. Si cada grupo se divide nuevamente, tendríamos 4 grupos de casas. Dividir cada uno de esos grupos nuevamente crearía 8 grupos. Si seguimos duplicando el número de grupos agregando más divisiones en cada nivel, tendremos 210 grupos de casas para cuando lleguemos al décimo nivel. Eso son 1024 hojas.\n",
    "\n",
    "Cuando dividimos las casas en muchas hojas, también tenemos menos casas en cada hoja. Las hojas con muy pocas casas harán predicciones que se acercan mucho a los valores reales de esas casas, pero pueden hacer predicciones muy poco confiables para nuevos datos (porque cada predicción se basa en solo unas pocas casas).\n",
    "\n",
    "Esto es un fenómeno llamado sobreajuste (overfitting), donde un modelo se ajusta casi perfectamente a los datos de entrenamiento, pero tiene un mal desempeño en la validación y otros nuevos datos. Por otro lado, si hacemos nuestro árbol muy poco profundo, no divide las casas en grupos muy distintos.\n",
    "\n",
    "En el extremo, si un árbol divide las casas en solo 2 o 4 grupos, cada grupo seguirá teniendo una amplia variedad de casas. Las predicciones resultantes pueden estar muy alejadas para la mayoría de las casas, incluso en los datos de entrenamiento (y también serán malas en la validación por la misma razón). Cuando un modelo no logra capturar distinciones y patrones importantes en los datos, por lo que tiene un mal rendimiento incluso en los datos de entrenamiento, eso se llama subajuste (underfitting).\n",
    "\n",
    "Dado que nos importa la precisión en nuevos datos, que estimamos a partir de nuestros datos de validación, queremos encontrar el punto óptimo entre el subajuste y el sobreajuste. Visualmente, queremos el punto más bajo de la curva de validación (roja) en la figura a continuación.\n",
    "\n",
    "Ejemplo\n",
    "Existen algunas alternativas para controlar la profundidad del árbol, y muchas permiten que algunas rutas a través del árbol tengan mayor profundidad que otras rutas. Pero el argumento **max_leaf_nodes** proporciona una forma muy sensata de controlar el sobreajuste frente al subajuste. Cuantas más hojas permitamos que haga el modelo, más nos moveremos desde el área de subajuste en el gráfico anterior hacia el área de sobreajuste.\n",
    "\n",
    "Podemos usar una función de utilidad para ayudar a comparar las puntuaciones de error absoluto medio (MAE) para diferentes valores de max_leaf_nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cae89141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def get_mae(max_nodos, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_nodos, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a3390f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max leaf nodes: 5  \t\t Mean Absolute Error:  385881\n",
      "Max leaf nodes: 50  \t\t Mean Absolute Error:  280417\n",
      "Max leaf nodes: 500  \t\t Mean Absolute Error:  262176\n",
      "Max leaf nodes: 5000  \t\t Mean Absolute Error:  278532\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    # crea el modelo\n",
    "    model.fit(train_X, train_y)\n",
    "    # entreno el modelo\n",
    "    preds_val = model.predict(val_X)\n",
    "    # predice\n",
    "    mae = mean_absolute_error(val_y, preds_val) #retorna\n",
    "    return(mae)\n",
    "\n",
    "# compare MAE with differing values of max_leaf_nodes\n",
    "for max_leaf_nodes in [5, 50, 500, 5000]:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X, test_X, train_y, test_y)\n",
    "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3888d8",
   "metadata": {},
   "source": [
    "De las opciones enumeradas, 500 es el número óptimo de hojas.\n",
    "\n",
    "Conclusión\n",
    "Aquí está el resumen: Los modelos pueden sufrir de:\n",
    "\n",
    "**Sobreajuste:** capturan patrones espurios que no se repetirán en el futuro, lo que lleva a predicciones menos precisas.\n",
    "**Subajuste:** no capturan patrones relevantes, lo que también lleva a predicciones menos precisas.\n",
    "Utilizamos datos de validación, que no se utilizan en el entrenamiento del modelo, para medir la precisión de un modelo candidato. Esto nos permite probar muchos modelos candidatos y quedarnos con el mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c8ca5b",
   "metadata": {},
   "source": [
    "Los árboles de decisión te enfrentan a una decisión difícil. Un árbol profundo con muchas hojas sobreajustará porque cada predicción proviene de datos históricos de solo unas pocas casas en su hoja. Pero un árbol superficial con pocas hojas tendrá un rendimiento deficiente porque no captura tantas distinciones en los datos sin procesar.\n",
    "\n",
    "Incluso las técnicas de modelado más sofisticadas de hoy en día enfrentan esta tensión entre el subajuste y el sobreajuste. Sin embargo, muchos modelos tienen ideas ingeniosas que pueden llevar a un mejor rendimiento. Vamos a analizar el bosque aleatorio como ejemplo. (RANDOM FOREST)\n",
    "\n",
    "El bosque aleatorio utiliza muchos árboles y realiza una predicción promediando las predicciones de cada árbol componente. Generalmente, tiene una precisión predictiva mucho mejor que un solo árbol de decisión y funciona bien con los parámetros predeterminados. Si sigues modelando, puedes aprender más modelos con un rendimiento aún mejor, pero muchos de ellos son sensibles a obtener los parámetros correctos.\n",
    "\n",
    "Has visto el código para cargar los datos varias veces. Al finalizar la carga de datos, tenemos las siguientes variables:\n",
    "\n",
    "train_X\n",
    "val_X\n",
    "train_y\n",
    "val_y\n",
    "\n",
    "Construimos un modelo de bosque aleatorio de manera similar a cómo construimos un árbol de decisión en scikit-learn, pero esta vez utilizando la clase RandomForestRegressor en lugar de DecisionTreeRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1b80cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202743.18372721455\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_model = RandomForestRegressor(random_state=1)\n",
    "forest_model.fit(train_X, train_y)\n",
    "melb_preds = forest_model.predict(test_X)\n",
    "print(mean_absolute_error(test_y, melb_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a511e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
